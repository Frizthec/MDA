{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vx_HUoeojbW7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "#import plotly.express as px\n",
        "import string\n",
        "#import spacy\n",
        "#nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "from gensim.parsing.preprocessing import strip_punctuation\n",
        "from gensim.parsing.preprocessing import strip_multiple_whitespaces\n",
        "from gensim.parsing.preprocessing import stem_text\n",
        "\n",
        "#from gensim.summarization.summarizer import summarize\n",
        "#from gensim.summarization import keywords\n",
        "\n",
        "#import networkx as nx\n",
        "\n",
        "import os\n",
        "import tqdm\n",
        "\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MetaDiscourseAnalysis:\n",
        "\n",
        "  def __init__(self):\n",
        "    self.CodeGloss = [\"matter\", \"fact\", \"called\", \"defined\", \"example\", \"instance\", \"mean\", \"ie\", \"i.e.\", \"i.e\", \"know\", \"know\", \"namely\", \"another\", \"way\", \"put\", \"say\", \"specifically\", \"such\", \"as\", \"that\", \"mean\", \"means\", \"viz\", \"viz.\"];\n",
        "    self.Endophorics = [\"chapter\", \"part\", \"section\", \"example\", \"fig\", \"figure\", \"fig.\", \"page\", \"table\", \"above\", \"before\", \"below\", \"earlier\", \"later\"];\n",
        "    self.Evidentials = [\"cite\", \"cited\", \"quoted\", \"quote\", \"according\"];\n",
        "    self.FrameMarkersSequencing = [\"chapter\", \"section\", \"part\", \"finally\", \"final\", \"first\", \"second\", \"third\", \"firstly\", \"secondly\", \"thirdly\", \"fourth\", \"fifth\", \"subsequent\", \"subsequently\", \"then\"];\n",
        "    self.FrameMarkersLabels = [\"all\", \"point\", \"stage\", \"far\", \"moment\", \"brief\", \"conclusion\", \"short\", \"summary\", \"now\", \"whole\", \"overall\", \"thus\", \"conclude\", \"repeat\", \"sum\", \"summarize\"];\n",
        "    self.FrameMarkersAnnounceGoals = [\"this\", \"aim\", \"desire\", \"focus\", \"goal\", \"intend\", \"intention\", \"objective\", \"purpose\", \"seek\", \"want\", \"wish\", \"would\", \"like\"];\n",
        "    self.FrameMarkersShiftTopics = [\"back\", \"digress\", \"regard\", \"move\", \"resume\", \"return\", \"revisit\", \"shift\", \"look\", \"closely\", \"turn\", \"regard\"];\n",
        "    self.FrameMarkers = self.FrameMarkersSequencing + self.FrameMarkersLabels + self.FrameMarkersAnnounceGoals + self.FrameMarkersShiftTopics\n",
        "    self.Transition = [\"accordingly\", \"according\", \"additionally\", \"again\", \"also\", \"alternatively\", \"although\", \"consequence\", \"result\", \"same\", \"time\", \"because\", \"besides\", \"but\", \"contrast\", \"by\", \"token\", \"consequently\", \"conversely\", \"equally\", \"equal\", \"even\", \"though\", \"further\", \"furthermore\", \"hence\", \"however\", \"addition\", \"contrast\", \"way\", \"leads\", \"likewise\", \"moreover\", \"nevertheless\", \"nonetheless\", \"contrary\", \"hand\", \"rather\", \"result\", \"similarly\", \"similar\", \"since\", \"so\", \"still\", \"result\", \"thereby\", \"therefore\", \"though\", \"thus\", \"whereas\", \"while\", \"yet\"];\n",
        "    self.AttitudeMarkers = [\"admittedly\", \"agree\", \"agrees\", \"agreed\", \"amazed\", \"amazing\", \"amazingly\", \"appropriate\", \"appropriately\", \"astonished\", \"astonishing\", \"astonishingly\", \"correctly\", \"curious\", \"curiously\", \"desirable\", \"desirably\", \"disappointed\", \"disappointing\", \"disappointingly\", \"disagree\", \"disagreed\", \"disagrees\", \"dramatic\", \"dramatically\", \"essential\", \"essentially\", \"even\", \"expected\", \"expectedly\", \"fortunate\", \"fortunately\", \"hopeful\", \"hopefully\", \"important\", \"importantly\", \"inappropriate\", \"inappropriately\", \"interesting\", \"interestingly\", \"prefer\", \"preferable\", \"preferably\", \"preferred\", \"remarkable\", \"remarkably\", \"shocked\", \"shocking\", \"shockingly\", \"striking\", \"strikingly\", \"surprised\", \"surprising\", \"surprisingly\", \"unbelievable\", \"unbelievably\", \"understandable\", \"understandably\", \"unexpected\", \"unexpectedly\", \"unfortunate\", \"unfortunately\", \"unusual\", \"unusually\", \"usual\"];\n",
        "    self.Emphatics=[\"actually\", \"always\", \"believe\", \"believed\", \"believes\", \"beyond doub t\", \"certain\", \"certainly\", \"clear\", \"clearly\", \"conclusively\", \"decidedly\", \"definite\", \"definitely\", \"demonstrate\", \"demonstrated\", \"demonstrates\", \"doubtless\", \"establish\", \"established\", \"evident\", \"evidently\", \"find\", \"finds\", \"found\", \"fact\", \"incontestable\", \"incontestably\", \"incontrovertible\", \"incontrovertibly\", \"indeed\", \"indisputable\", \"indisputably\", \"know\", \"known\", \"must\", \"never\", \"obvious\", \"obviously\", \"course\", \"prove\", \"proved\", \"proves\", \"realize\", \"realized\", \"realizes\", \"really\", \"show\", \"showed\", \"shown\", \"shows\", \"sure\", \"surely\", \"think\", \"thinks\", \"thought\", \"truly\", \"true\", \"undeniable\", \"undeniably\", \"undisputedly\", \"undoubtedly\", \"doubt\"];\n",
        "    self.PersonMarkers = [\"i\", \"we\", \"me\", \"my\", \"our\", \"mine\", \"us\", \"you\", \"your\", \"author\", \"authors\", \"author's\", \"writer\", \"writer's\", \"writers\", \"they\", \"them\", \"he\", \"she\"];\n",
        "    self.Engagement = [\"reader\", \"readers\", \"add\", \"allow\", \"analyse\", \"apply\", \"arrange\", \"assess\", \"assume\", \"by the way\", \"calculate\", \"choose\", \"classify\", \"compare\", \"connect\", \"consider\", \"consult\", \"contrast\", \"define\", \"demonstrate\", \"determine\", \"do not\", \"develop\", \"employ\", \"ensure\", \"estimate\", \"evaluate\", \"find\", \"follow\", \"go\", \"have\", \"imagine\", \"incidentally\", \"increase\", \"input\", \"insert\", \"integrate\", \"key\", \"let\", \"let's\", \"lets\", \"look\", \"mark\", \"measure\", \"mount\", \"must\", \"need\", \"note\", \"notice\", \"observe\", \"one's\", \"ones\", \"order\", \"ought\", \"our \", \"pay\", \"picture\", \"prepare\", \"recall\", \"recover\", \"refer\", \"regard\", \"remember\", \"remove\", \"review\", \"see\", \"select\", \"set\", \"should\", \"show\", \"suppose\", \"state\", \"take\", \"think\", \"turn\", \"us\", \"use\", \"we\", \"you\", \"your\"];\n",
        "    self.Hedges = [\"about\", \"almost\", \"apparent\", \"apparently\", \"appear\", \"appeared\", \"appears\", \"approximately\", \"argue\", \"argued\", \"argues\", \"around\", \"assume\", \"assumed\", \"broadly\", \"certain\", \"extent\", \"level\", \"claim\", \"claimed\", \"claims\", \"could\", \"couldn't\", \"doubt\", \"doubtful\", \"essentially\", \"estimate\", \"estimated\", \"fairly\", \"feel\", \"feels\", \"felt\", \"frequently\", \"perspective\", \"generally\", \"guess\", \"indicate\", \"indicated\", \"indicates\", \"general\", \"most\", \"opinion\", \"view\", \"largely\", \"likely\", \"mainly\", \"may\", \"maybe\", \"might\", \"mostly\", \"often\", \"ought\", \"perhaps\", \"plausible\", \"plausibly\", \"possible\", \"possibly\", \"postulate\", \"postulated\", \"postulates\", \"presumable\", \"presumably\", \"probable\", \"probably\", \"quite\", \"rather \", \"relatively\", \"roughly\", \"seems\", \"should\", \"sometimes\", \"somewhat\", \"suggest\", \"suggested\", \"suggests\", \"suppose\", \"supposed\", \"supposes\", \"suspect\", \"suspects\", \"tend t o\", \"tended to\", \"tends to\", \"knowledge\", \"typical\", \"typically\", \"uncertain\", \"uncertainly\", \"unclear\", \"unclearly\", \"unlikely\", \"usually\", \"would\", \"wouldn't\", \"wouldnt\"];\n",
        "\n",
        "  def authorial_stance(self, text):\n",
        "    epsilon = 0.000000000001;\n",
        "    words = strip_multiple_whitespaces(strip_punctuation(text.lower())).split()\n",
        "    pc_person_markers = np.round(float(len([i for i in words if i in self.PersonMarkers])/(len(text.split())+epsilon))*100,3)\n",
        "    pc_code_gloss = np.round(float(len([i for i in words if i in self.CodeGloss])/(len(text.split())+epsilon))*100,3)\n",
        "    pc_att_markers = np.round(float(len([i for i in words if i in self.AttitudeMarkers])/(len(text.split())+epsilon))*100,3)\n",
        "    pc_endophorics = np.round(float(len([i for i in words if i in self.Endophorics])/(len(text.split())+epsilon))*100,3)\n",
        "    pc_hedges = np.round(float(len([i for i in words if i in self.Hedges])/(len(text.split())+epsilon))*100,3)\n",
        "    pc_emphatics = np.round(float(len([i for i in words if i in self.Emphatics])/(len(text.split())+epsilon))*100,3)\n",
        "    pc_frame_markers = np.round(float(len([i for i in words if i in self.FrameMarkers])/(len(text.split())+epsilon))*100,3)\n",
        "    pc_evidentials = np.round(float(len([i for i in words if i in self.Evidentials])/(len(text.split())+epsilon))*100,3)\n",
        "\n",
        "    pc_interactional = np.array([pc_person_markers, pc_hedges, pc_emphatics, pc_att_markers])\n",
        "    pc_interactive = np.array([pc_code_gloss, pc_endophorics, pc_evidentials, pc_frame_markers])\n",
        "\n",
        "    interactional = np.sum(pc_interactional, axis=0)\n",
        "    interactive = np.sum(pc_interactive, axis=0)\n",
        "\n",
        "    return np.round(interactional,3), np.round(interactive,3), len(words)\n",
        "\n",
        "  def moving_average(self, x, w):\n",
        "    return np.convolve(x, np.ones(w), 'valid') / w\n",
        "\n",
        "  # Auxiliary functions for preprocessing.\n",
        "  def log(self, text):\n",
        "    return print(text), print(strip_multiple_whitespaces(strip_punctuation(text.lower())).split())\n",
        "\n",
        "  def get_sentences(self, text):\n",
        "    mystr = text.replace(' ', '')\n",
        "    return mystr.split(\".\")\n",
        "\n",
        "  def get_sentences_from_txt(self, filename):\n",
        "    sentences = []\n",
        "    with open(filename, 'r') as f:\n",
        "      for line in f:\n",
        "        sentences.extend(line.split('.'))\n",
        "    return sentences"
      ],
      "metadata": {
        "id": "ix839WA_jiX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic analysis."
      ],
      "metadata": {
        "id": "deScirwAHj_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "md = MetaDiscourseAnalysis()\n",
        "text = \" Carecredit CareCredit is here to help you pay for treatments and procedures your insurance doesn't cover. We offer No Interest* financing or low minimum monthly payment options so you can get what you want, when you want it. You can even use CareCredit for your family and favorite pet. \"\n",
        "md.log(text)\n",
        "#md.authorial_stance(text)\n",
        "md.get_sentences(text)"
      ],
      "metadata": {
        "id": "IcNmDxozj-o3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sen = text.split(\".\")\n",
        "for s in sen:\n",
        "  print(md.authorial_stance(s))"
      ],
      "metadata": {
        "id": "sTiEb1D8s_Qz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sen = md.get_sentences_from_txt('yale_finmkt_001.txt')\n",
        "pc_interactional = []\n",
        "for s in sen[0:150]:\n",
        "  pc_interactional.append(md.authorial_stance(s)[0])\n",
        "\n",
        "# Moving avg.\n",
        "w=5\n",
        "np.convolve(pc_interactional, np.ones(w), 'valid') / w"
      ],
      "metadata": {
        "id": "JDnViNi5to7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def MDMovingAverageInteractional(filename, w):\n",
        "  sentences = []\n",
        "  with open(filename, 'r') as f:\n",
        "    for line in f:\n",
        "      sentences.extend(line.split('.'))\n",
        "\n",
        "  pc_interactional = []\n",
        "  for s in sentences:\n",
        "    pc_interactional.append(md.authorial_stance(s)[0])\n",
        "\n",
        "  return np.convolve(pc_interactional, np.ones(w), 'valid') / w"
      ],
      "metadata": {
        "id": "z8t7ClN8Fk4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(MDMovingAverageInteractional('yale_physics_001.txt', 5), 'b*-')\n",
        "plt.plot(MDMovingAverageInteractional('yale_finmkt_001.txt', 5), 'r+-')\n"
      ],
      "metadata": {
        "id": "2atVvqYGGA0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.lib.stride_tricks import sliding_window_view\n",
        "x = np.arange(6)\n",
        "x\n",
        "sliding_window_view(x, 3)"
      ],
      "metadata": {
        "id": "B0ldPq1LygiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(pd.Series(pc_interactional).rolling(10).std())"
      ],
      "metadata": {
        "id": "udtYePhaHZaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using OpenAI whisper and Pytube. [under construction]"
      ],
      "metadata": {
        "id": "ERZ14LiH2rr_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "! pip install --upgrade pytube\n",
        "! pip install ffmpeg\n",
        "! pip install pytubefix"
      ],
      "metadata": {
        "id": "HgV4XGvSttQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "! pip install -U openai-whisper"
      ],
      "metadata": {
        "id": "Yvf_0AMAuUha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "model = whisper.load_model(\"tiny\")"
      ],
      "metadata": {
        "id": "47OZTA4cudxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pytubefix import YouTube\n",
        "from pytubefix.cli import on_progress\n",
        "\n",
        "url = \"https://youtu.be/NK-BxowMIfg?si=aAhaJDOtVJjt5Azg\"\n",
        "\n",
        "yt = YouTube(url, on_progress_callback = on_progress)\n",
        "print(yt.title)\n",
        "\n",
        "ys = yt.streams.get_audio_only()\n",
        "ys.download(mp3=True) # pass the parameter mp3=True to save in .mp3"
      ],
      "metadata": {
        "id": "Tx9Rgbq-ulTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! rm *_30.mp3\n",
        "! ffmpeg -ss 0 -t 00:05:00 -i electrostatics.mp3 electrostatics_300.mp3"
      ],
      "metadata": {
        "id": "NNsEBnAcx7Rj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.transcribe(\"electrostatics_300.mp3\")\n",
        "transcript = result[\"text\"]"
      ],
      "metadata": {
        "id": "4mG5TbiawQTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sen = transcript.split(\".\")\n",
        "pc_interactional = []\n",
        "for s in sen:\n",
        "  pc_interactional.append(md.authorial_stance(s)[0])"
      ],
      "metadata": {
        "id": "iI3S6oR8xte0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6dPC62ZIzPPn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}